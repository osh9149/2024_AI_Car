{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/osh9149/2024_AI_Car/blob/main/aicar_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHhTZZmYiHjX"
      },
      "source": [
        "<STEP 1> Google 드라이브 연결, 이미지 파일 압축 풀기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYGI3Ajyw7SI",
        "outputId": "4ce2be53-c4c1-4ee4-9842-3cfc6167a851"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVUvp1PNiP5x"
      },
      "outputs": [],
      "source": [
        "epochN = None; learnRate = None                                                 # epochN = 300, learnRate = 0.0005/0.0010/0.0015/0.0020/0.0025\n",
        "import glob, zipfile\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')                                                   # Google Drive 연결\n",
        "imageDir = 'aicar'; outDir = '/content/drive/MyDrive/'+imageDir                 # Google Drive 에서 도로 이미지가 저장된 디렉터리 이름, 학습 파일, plot이미지 저장 위치\n",
        "fileList = glob.glob(outDir+'/*.zip'); print(f'자율주행 프로젝트는 {len(fileList)} 개 입니다.')  # 검사 조건에 만족하는 파일 리스트 생성, 프로젝트 개수 프린트\n",
        "for t in fileList:                                                              # 프로젝트 이름 프린트\n",
        "    u = t.split('/'); v = u[-1]; w = v.split('.'); p = w[-2]; print(p)          # 파일 이름 추출 '/' 문자를 기준으로 분리하여 리스트 생성\n",
        "project = input('자율주행 프로젝트 이름을 입력하세요:')                         # 자율 주행 프로젝트 이름 입력하고 [Enter]키 입력\n",
        "if project == '': project = p                                                   # 이름 입력하지 않고 [Enter]키 입력하면 표시된 마지막 파일을 사용\n",
        "local_zip =  '/content/drive/MyDrive/'+imageDir+'/'+project+'.zip'; print(local_zip) # 코랩 aicar 폴더안의 다운받은 Zip 파일 경로(path)\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r'); zip_ref.extractall(); zip_ref.close()     # 디폴트 폴더에 압축 풀기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZFNRpDrwx_o"
      },
      "source": [
        "<STEP 2> 라이브러리 가져오기(Import)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQZoAksnjCi9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import fnmatch\n",
        "import pickle\n",
        "import time\n",
        "import numpy as np\n",
        "import cv2 as cv                                                                # Open Cv 영상처리 라이브러리\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "%matplotlib inline\n",
        "from PIL import Image\n",
        "\n",
        "print(f'Python Version:     {sys.version}')                                     # Python Version\n",
        "print(f'OpenCV version:     {cv.__version__}')                                  # Open CV version\n",
        "print(f'Pytorch version:    {torch.__version__}')                               # Pytorch version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA5CRv_sw3XN"
      },
      "source": [
        "<STEP 3> 이미지 데이터 조향각 추출"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3TvCY7hQjkYx"
      },
      "outputs": [],
      "source": [
        "dataDir = '/content/'+project                                                   # colab 내부 프로젝트 디렉터리\n",
        "with open(f'{dataDir}/_{project}.pickle', 'rb') as f:                           # pickle 파일\n",
        "    x_exam_Image = pickle.load(f)                                               # 시험(Test) 이미지 파일 이름 리스트\n",
        "    x_valid_Image = pickle.load(f)                                              # 평가(Valid) 이미지 파일 이름 리스트\n",
        "    x_train_Image = pickle.load(f)                                              # 훈련(Train) 이미지 파일 이름 리스트\n",
        "    p = pickle.load(f)                                                          # 파라메터 리스트\n",
        "if epochN == None:    epochN =    p[0]                                          # 학습회수\n",
        "if learnRate == None: learnRate = p[1]                                          # 학습 비율 0.0005/0.0010/0.0015/0.0020/0.0025\n",
        "#-------------------------------------------------------------------------------\n",
        "y_exam_Angle=[]\n",
        "y_valid_Angle=[]\n",
        "y_train_Angle = []\n",
        "for f in x_exam_Image:                   # 시험용 이미지 파일 이름에서 각도값\n",
        "    y_exam_Angle.append(int(f[-7:-4]))\n",
        "for f in x_valid_Image:                  # 평가용 이미지 파일 이름에서 각도값\n",
        "    y_valid_Angle.append(int(f[-7:-4]))\n",
        "for f in x_train_Image:                  # 훈련용 이미지 파일 이름에서 각도값\n",
        "    y_train_Angle.append(int(f[-7:-4]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yP5tACd_xMJh"
      },
      "source": [
        "<STEP 4> Nvidia CNN 모델 구성, 딥러닝"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxPuU_aI0iWv"
      },
      "outputs": [],
      "source": [
        "# Pytorch device 설정\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'{device} is available')\n",
        "\n",
        "# Nvidia CNN 모델 구성 ---------------------------------------------------------\n",
        "class NvidiaModel(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(NvidiaModel, self).__init__()\n",
        "\n",
        "      # elu=Expenential Linear Unit, similar to leaky Relu\n",
        "      # skipping 1st hiddel layer (nomralization layer), as we have normalized the data\n",
        "\n",
        "      # Convolution Layers\n",
        "      self.layer1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=3, out_channels=24, kernel_size=(5, 5), stride=(2, 2)),\n",
        "        nn.ELU(inplace=True),\n",
        "        nn.Conv2d(in_channels=24, out_channels=36, kernel_size=(5, 5), stride=(2, 2)),\n",
        "        nn.ELU(inplace=True),\n",
        "        nn.Conv2d(in_channels=36, out_channels=48, kernel_size=(5, 5), stride=(2, 2)),\n",
        "        nn.ELU(inplace=True),\n",
        "        nn.Conv2d(in_channels=48, out_channels=64, kernel_size=(3, 3)),\n",
        "        nn.ELU(inplace=True),\n",
        "        nn.Dropout(0.2),\n",
        "        nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3, 3)),\n",
        "        nn.ELU(inplace=True)\n",
        "      )\n",
        "\n",
        "      # Fully Connected Layers\n",
        "      self.layer2 = nn.Sequential(\n",
        "        # nn.Flatten(),\n",
        "        nn.Dropout(0.2),\n",
        "        nn.Linear(in_features=18 * 64, out_features=100),\n",
        "        nn.ELU(inplace=True),\n",
        "        nn.Linear(in_features=100, out_features=50),\n",
        "        nn.ELU(inplace=True),\n",
        "        nn.Linear(in_features=50, out_features=10),\n",
        "        nn.ELU(inplace=True)\n",
        "      )\n",
        "\n",
        "      # Output Layer\n",
        "      self.layer3 = nn.Sequential(\n",
        "        nn.Linear(in_features=10, out_features=1)\n",
        "      )\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.layer1(x)\n",
        "      x = x.view(x.shape[0], -1)\n",
        "      x = self.layer2(x)\n",
        "      x = self.layer3(x)\n",
        "\n",
        "      return x\n",
        "\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "def imgPaths(fGroup):\n",
        "    r = []\n",
        "    for filename in fGroup:\n",
        "        r.append(os.path.join(dataDir, filename))                               # 파일 경로(path)를 화일 이름 앞에 부착하여 리스트에 추가\n",
        "    return(r)\n",
        "\n",
        "# 학습 데이터 생성 -------------------------------------------------------------\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, imageList, angleList):\n",
        "        self.imageList = imgPaths(imageList)\n",
        "        self.angleList = angleList\n",
        "\n",
        "        for i in range(len(imageList)):\n",
        "            # print(i, self.imageList[i])\n",
        "            image = cv.imread(self.imageList[i])\n",
        "            image = image / 255\n",
        "\n",
        "            self.imageList[i] = image\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imageList)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        images = torch.FloatTensor(self.imageList[index]).permute(2,0,1)\n",
        "        angles = torch.FloatTensor([self.angleList[index]])\n",
        "\n",
        "        return images, angles\n",
        "\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "class EarlyStopping:\n",
        "    \"\"\"주어진 patience 이후로 validation loss가 개선되지 않으면 학습을 조기 중지\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path=f'{outDir}/_{project}_model_check.pt'):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): validation loss가 개선된 후 기다리는 기간\n",
        "                            Default: 7\n",
        "            verbose (bool): True일 경우 각 validation loss의 개선 사항 메세지 출력\n",
        "                            Default: False\n",
        "            delta (float): 개선되었다고 인정되는 monitered quantity의 최소 변화\n",
        "                            Default: 0\n",
        "            path (str): checkpoint저장 경로\n",
        "                            Default: 'checkpoint.pt'\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'Early Stopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''validation loss가 감소하면 모델을 저장한다.'''\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        # torch.save(model, self.path)\n",
        "        self.val_loss_min = val_loss\n",
        "\n",
        "# 모델 학습 --------------------------------------------------------------------\n",
        "def learnProc():\n",
        "  model = NvidiaModel().to(device)\n",
        "\n",
        "  train_dataset = CustomDataset(x_train_Image, y_train_Angle)\n",
        "  train_loader = DataLoader(train_dataset, batch_size=len(x_train_Image))\n",
        "\n",
        "  valid_dataset = CustomDataset(x_valid_Image, y_valid_Angle)\n",
        "  valid_loader = DataLoader(valid_dataset, batch_size=len(x_valid_Image))\n",
        "\n",
        "  optimizer = optim.Adam(model.parameters(), lr=learnRate)\n",
        "  criterion = nn.MSELoss().to(device)\n",
        "\n",
        "  early_stopping = EarlyStopping(patience=30, verbose=True)\n",
        "\n",
        "  # EPOCHS = epochN\n",
        "  EPOCHS = 300\n",
        "  train_losses = []\n",
        "  valid_losses = []\n",
        "  avg_train_losses = []\n",
        "  avg_valid_losses = []\n",
        "  for epoch in range(1, EPOCHS + 1):\n",
        "      # 학습\n",
        "      model.train()\n",
        "\n",
        "      for batch_idx, (data, target) in enumerate(train_loader):\n",
        "          data, target = data.to(device), target.to(device)\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          output = model(data)\n",
        "\n",
        "          loss = criterion(output.to(torch.float32), target.to(torch.float32))\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          train_losses.append(loss.item())\n",
        "\n",
        "      # 검증\n",
        "      model.eval()\n",
        "\n",
        "      with torch.no_grad():\n",
        "        for data, target in valid_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "\n",
        "            output = model(data)\n",
        "\n",
        "            loss = criterion(output.to(torch.float32), target.to(torch.float32))\n",
        "\n",
        "            valid_losses.append(loss.item())\n",
        "\n",
        "      train_loss = np.average(train_losses)\n",
        "      valid_loss = np.average(valid_losses)\n",
        "      avg_train_losses.append(train_loss)\n",
        "      avg_valid_losses.append(valid_loss)\n",
        "\n",
        "      epoch_len = len(str(EPOCHS))\n",
        "\n",
        "      print_msg = (f'[{epoch:>{epoch_len}}/{EPOCHS:>{epoch_len}}] ' +\n",
        "                      f'train_loss: {train_loss:.6f} ' +\n",
        "                      f'valid_loss: {valid_loss:.6f}')\n",
        "\n",
        "      print(print_msg)\n",
        "\n",
        "      train_losses = []\n",
        "      valid_losses = []\n",
        "\n",
        "      early_stopping(valid_loss, model)\n",
        "\n",
        "      if early_stopping.early_stop:\n",
        "          print(\"Early stopping\")\n",
        "          break\n",
        "\n",
        "  return {'loss':avg_train_losses, 'val_loss':avg_valid_losses}\n",
        "\n",
        "# 학습 시작---------------------------------------------------------------------\n",
        "print()\n",
        "print('시험 이미지 개수:',len(x_exam_Image))\n",
        "print('평가 이미지 개수:',len(x_valid_Image))\n",
        "print('훈련 이미지 개수:',len(x_train_Image))\n",
        "print('학습 비율=', learnRate)\n",
        "print('학습 회수=', epochN)\n",
        "print()\n",
        "startTime = time.time()                                                         # 학습 시작 시간 저장\n",
        "history = learnProc()                                                           # 학습 시작\n",
        "elapsedTime = int(time.time() - startTime)                                      # 학습 경과 시간 저장\n",
        "lossMin = min(history['loss'])                                                  # 딕셔너리 history의 'loss'키 데이터는 리스트, 최소값\n",
        "val_lossMin = min(history['val_loss'])                                          # 딕셔너리 history의 'val_loss'키 데이터는 리스트, 최소값\n",
        "#-------------------------------------------------------------------------------\n",
        "plt.plot(history['loss'],color='blue')\n",
        "plt.plot(history['val_loss'],color='red')\n",
        "plt.legend([f'training loss Min: {lossMin:0.2f}', f'validation loss Min: {val_lossMin:0.2f}'])\n",
        "plt.savefig(f'{outDir}/_{project}_result.png')                                  # plot 이미지 저장"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqDQYO1MxjHF"
      },
      "source": [
        "<STEP 5> 학습 결과 표시, 테스트 파일 각도 예측"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGICxni7ikSK"
      },
      "outputs": [],
      "source": [
        "def resultShow():\n",
        "  '''\n",
        "  학습 완료후 통계자료 표시\n",
        "  '''\n",
        "\n",
        "  from torchsummary import summary                                              # Nvidia Model 의 Summary를 표시\n",
        "  model = NvidiaModel().to(device)\n",
        "  summary(model,(3, 66, 200))\n",
        "\n",
        "  test_dataset = CustomDataset(x_exam_Image, y_exam_Angle)\n",
        "  test_loader = DataLoader(test_dataset, batch_size=len(x_exam_Image))\n",
        "\n",
        "  model = NvidiaModel().to(device)\n",
        "  model.load_state_dict(torch.load(f'{outDir}/_{project}_model_check.pt'))      # 모델 파일\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  y_pred = []\n",
        "  y_target = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            print('예측 조향각:', output.to(device).cpu().numpy())\n",
        "            print('입력 조향각:', target.to(device).cpu().numpy())\n",
        "\n",
        "            for output_data, target_data in zip(output.to(device).cpu().numpy(), target.to(device).cpu().numpy()):\n",
        "              y_pred.append(output_data)\n",
        "              y_target.append(target_data)\n",
        "\n",
        "  mse = mean_squared_error(y_target, y_pred)\n",
        "  r2s = r2_score(y_target, y_pred)\n",
        "  #-----------------------------------------------------------------------------\n",
        "  print('\\n표준 편차:', f'{mse:.2}')\n",
        "  print('회귀 결정 계수:', f'{r2s:.2%}')\n",
        "  #-----------------------------------------------------------------------------\n",
        "  fig, axes = plt.subplots(1, len(x_exam_Image), figsize=(30, 2+3))\n",
        "  xTImg = imgPaths(x_exam_Image)                                                # 파일 이름 앞에 경로(path) 추가\n",
        "  for x, c in enumerate(xTImg):\n",
        "    yuv_image = cv.imread(c, cv.IMREAD_UNCHANGED)                               # 테스트 이미지 읽기\n",
        "    bgr_image = cv.cvtColor(yuv_image, cv.COLOR_YUV2BGR)                        # YUV 이미지를 BGR 형식으로 변환\n",
        "    rgb_image = cv.cvtColor(bgr_image, cv.COLOR_BGR2RGB)                        # MatPlot Lib 에서 표시되는 RGB 형식으로 변환\n",
        "    axes[x].imshow(rgb_image)\n",
        "    t = x_exam_Image[x] +' / E:'+str(int(y_pred[x]))\n",
        "    axes[x].set_title(t)\n",
        "    axes[x].xaxis.set_ticks([])\n",
        "    axes[x].yaxis.set_ticks([])\n",
        "\n",
        "if len(x_exam_Image): resultShow()\n",
        "print(\"학습 소요 시간:\", int(elapsedTime/60), '분', elapsedTime%60, '초' )      # 학습 소요시간 프린트"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}